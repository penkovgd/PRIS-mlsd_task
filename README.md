# Дизайн ML системы - Кейс №1: Автомодерация в соцсетях


## Состав команды

- Файзулин Радмир Русланович - Product Owner
- Пеньков Георгий - Data Scientist
- Зотов Михаил - Software Architect

# Описание кейса

**Бизнес-цель:**  
Автоматизировать мониторинг пользовательских реакций на контент (посты, рекламу, новости) в соцсети, чтобы оперативно выявлять негатив, улучшать модерацию и повышать вовлеченность аудитории.

**Описание текущего процесса:**  
Сейчас анализ тональности проводится вручную (модераторы читают выборочные комментарии) или не проводится вообще → медленно, дорого, субъективно.  
Количество комментариев, поступающих ежедневно на модерацию в среднем доходит до 500_000.  
При этом со стороны РКН ведется мониторинг качества модерации ресурса, и потенциально неприемлемые комментарии могут навлечь серьезные штрафы и санкции. 

# Построенные диаграммы

- Бизнес процессы – BPMN:
    - До: ![BPMN_before](diagrams\BPMN_before.svg)
    - После: ![BPMN_after](diagrams\bpmn_after.svg)
- Структура данных –  ERD: ![ERD](diagrams\ERD.png)
- Архитектура системы (свободная нотация): ![Architecture](diagrams\Architecture.png)
- Структурная UML-диаграмма – диаграмма классов: ![class_uml](diagrams\class_uml.png)
- Поведенческая UML-диаграмма – диаграмма последовательности: ![sequence_diagram.png](diagrams\sequence_diagram.png)


# Цели и предпосылки


## Зачем идем в разработку продукта?
Увеличить эффективность с помощью автоматизации: Сейчас модерация комментариев проводится выборочно, что неэффективно при 500K комментариев в день.

Снизить риски: РКН может наложить штрафы за неприемлемый контент, который не был вовремя обнаружен.

Повысить вовлеченность: Анализ тональности поможет адаптировать контент под аудиторию.

А также экономия на зарплате модераторов.


## Почему станет лучше, чем сейчас, от использования ML?
Скорость: ML-модель обрабатывает тысячи комментариев в секунду.
Объективность: Исключается человеческий фактор в оценке тональности.
Масштабируемость: Система справится с ростом нагрузки без пропорционального увеличения затрат.
Экономия: Система автоматизирована, поэтому не придется платить множеству модераторов


## Какие бизнес-требования и ограничения вы видите?
**Бизнес-требования**

- Хотим, чтобы негативные комментарии точно скрывались,
- Поддержка русского языка,
- Хотим понимать, как принимаются решения,
- Хотим получить указанные преимущества, по сравнению с улучшеной модерацией

**Ограничения**

Модератор-человек все же лучше справится с этой работой, так что "точность" может упасть.

## Какие функциональные требования и нефункциональные требования вы видите?
**Функциональность:**
- Классификация комментариев: негатив/позитив  
- Автоматизация: загруженный комментарий автоматически проходит проверку 

**Нефункциональные:**
- Метрика F1 > 0.85
- Масштабируемость до 500K+ комментариев/день  
- Latency < 1 сек  
- Доступность 99.9%  


## Как бы вы построили процесс пилота? Какие критерии успеха выбрали бы?
**Этапы:**  
1. Запуск на 10% трафика  
2. A/B-тест: модель vs люди  
3. Оценка нагрузки на инфраструктуру  

**Критерии успеха:**  
F1 > 0.85  
50% снижение ручной модерации  
Обработка 100K комментов за < 5 мин  


## Что, по вашему мнению, должно входить в итерацию работы на MVP, а что остаться техническим долгом?
**MVP**
- Базовая классификация (негатив/позитив),
- Интеграция с API модерации, автоматизация

**Техдолг**
- Улучшение модели (сарказма, контекст и пр.)
- Интерпретируемость модели
- Админ-панель, дашборды

# Методология


## Что делаем с технической точки зрения: рекомендательная система, поиск аномалий, регрессия, классификация, и др?

**Наш выбор: классифкация текста (бинарная)**

**Методы - ML-подход:**  
- Fine-tuning BERT/RuBERT 
- Резервный вариант: CatBoost + TF-IDF (он легковесный)


## Какие данные вам нужны? Без чего точно нельзя решить задачу?
**Данные:**  
- Обязательно: размеченные комментарии (10K+ примеров, негативные/позитивные)  
- Опционально: контекст комментария (автор, пост)


## Какие метрики качества (метрики машинного обучения) используем и как они связаны с бизнес-результатом?
**Метрики:**  
Recall -  Минимизация пропусков нарушений (важно не пропустить негативный коммент)

F1-score - Баланс между Precision и Recall

AUC-ROC	- Качество ранжирования опасных комментов


## Какие могут быть риски на этапе анализа и моделирования и что планируем с этим делать?
**Риски и решения**
- Низкое качество на сарказме/сленге
Решение: досбор датасета с сложными случаями

- Переобучение на специфичных данных
Решение: регуляризация модели

# Подготовка пилота


## Способ оценки пилота
A/B-тест: сравнение эффективности модели и модераторов.
Метрики:
- % обнаруженных нарушений
- время реакции на инциденты

## Что считаем успешным пилотом
**Успешный пилот**

Качество: F1 > 0.85

Скорость: Обработка 100K комментов за < 5 мин.

Снижение нагрузки: Меньше 50% комментов уходит на ручную проверку.


# Внедрение для production системы

## Архитектура решения

Система состоит из следующих компонентов    :

- API компонент - сервисы автомодерации + gateway (FastAPI)
- ML-worker (контейнеры в Kubernetes, модель классификации)
- Хранилища
    - PostgreSQL (хранение комментариев + модерации по ним)
    - Redis (хранение celery задач + хранение результата worker'ов)
- Очередь задач (Celery + Redis) - передача запросов на модерацию от сервиса автомодерации (producer) к ml-worker'ам (consumer)


## Описание инфраструктуры и масштабируемости: Какая инфраструктура выбрана и почему, плюсы и минусы

Классификатор: GPU-сервер для BERT
Почему?
- BERT и аналогичные трансформеры требуют вычислительных мощностей GPU для эффективного инференса.
Плюсы:
- Высокая скорость обработки
- Поддержка современных фреймворков
- Энергоэффективность
Минусы:
- Дороже CPU
- Требует оптимизации (например, через TensorRT для максимальной скорости)


База данных: PostgreSQL
Почему?
- Нужна реляционная структура для хранения нарушений с возможностью сложных запросов (анализ по пользователям, времени, типам нарушений).
Плюсы:
- Надежность
- Богатый функционал (индексы, полнотекстовый поиск)
- Интеграция с аналитическими инструментами (Metabase, Tableau)
Минусы:
- Сложнее масштабировать горизонтально (но для 500K записей/день вертикального scaling достаточно)
- Не самая высокая скорость для key-value сценариев (если нужны миллионы операций в секунду – лучше Redis как кэш)

Масштабируемость: Kubernetes
Почему?
- Обработка комментариев – неравномерная нагрузка (пики при публикации вирусного контента).
- Kubernetes автоматически масштабирует под нагрузку
Плюсы:
- Горизонтальное масштабирование (добавляем ноды при росте трафика)
- Отказоустойчивость (автоперезапуск упавших сервисов)
- Гибкость (можно развернуть hybrid cloud: часть в Yandex Cloud, часть на своих серверах)
Минусы:
- Сложность настройки (требуется DevOps-экспертиза)
- Накладные расходы

## Требования к системе
SLA: 99.9%.

RPS: 100+ запросов в секунду.

Latency: < 500 мс.

## Риск - Решение
Рост нагрузки - Автоскейлинг + кеширование

Высокая latency - оптимизация модели + поиск "слабого звена"